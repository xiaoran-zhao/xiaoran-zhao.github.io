The fusion of scalable computing infrastructure, big data, and artificial intelligence has boosted the development and application of data science and advanced data analytics. However, the recently emerging threats on the privacy, security, and trust (PST) of the data and the analytics models have shown a dramatically increasing trend with the wide deployment of data analytics applications.Specifically, the PST attacks on data or models such as model inversion attacks, membership inference attacks, data poisoning attacks, evasion attacks, and model backdoors, have severely made advanced data analytics highly vulnerable, particularly in common scenarios where data are distributed or computation is outsourced like MLaaS (Machine Learning as a Service). On the other hand, defence solutions are proposed as new computing schemes, PST frameworks, algorithms, and methods. For example, differential privacy, federated learning, and machine unlearning are proposed for privacy protection in data analytics, and adversarial machine learning is proposed to achieve robust, secure, and trustworthy data analytics. Given the importance and urgence, this special issue aims to provide a venue for researchers, practitioners and developers from different background areas relevant to PST and data analytics to exchange their latest experience, research ideas, and synergic research and development on fundamental issues and applications about privacy, security, and trust issues in data analytics, as a strong supplement to the main train of data science and advanced analytics.

This special session mainly focuses on the discussions of privacy, security, and trust in data analytics, which generally covers (but not limited to) the topics in privacy-preserving technology, privacy attacks, federated learning, machine unlearning, data poisoning attacks, model evasion attacks, adversarial learning, model robustness, secure machine learning integrating cryptographic techniques, blockchain techniques protection PST of data and models, etc. This special session invites authors to submit original research work that demonstrate and explore current advances in all related areas mentioned above.

Topics of interest include, but are not limited to:
- New privacy, security and trust opportunities and challenges in data analytics
- Novel theories and modelling for privacy, security, and trust in data analytics
- Private, secure, and trust deep learning for data analytics
- Privacy-preserving data mining and machine learning
- Federated/collaborative learning
- Machine unlearning
- Adversarial machine learning for robust data analytics
- Transfer learning for private, secure, and trust data analytics
- Data poisoning and model evasion attacks and defences
- Cryptographic techniques based private, secure, and trust data analytics
- Privacy, security, and trust management for data analytics
- Blockchain for privacy, security, and trust in data analytics
- Real-world applications for private, secure and trust data analytics
- Privacy, security and privacy issues, trends, and challenges in data analytics


#### Steering Committees
- Guanfeng Liu, Macquarie University, Australia 
- Xuyun Zhang, Macquarie University, Australia

#### General Chairs
- Lianyong Qi, China University of Petroleum (East China), China 
- Lina Yao, Data 61, CSIRO, Australia
- Shichao Pei, University of Massachusetts Boston, USA 

#### Program Chairs
- Pengpeng Zhao, Soochow University, China
- Tong Chen, The University of Queensland, Australia
- Xiyuan Hu, Nanjing University of Science and Technology, China

#### Important Dates
- Paper Submission: May 20, 2024
- Paper Notification: July 24, 2024
- Paper Camera-ready: August 21, 2024

#### Paper Submission
All papers should be submitted electronically via EasyChair portal link: https://easychair.org/conferences/?conf=pstda2024 .

The length of each paper should be no more than ten (10) pages and should be formatted following the standard 2-column U.S. letter style of IEEE Conference template. For further information and instructions, see the IEEE Proceedings Author Guidelines.

All submissions will be blind reviewed by the Program Committee on the basis of technical quality, relevance to the conference's topics of interest, originality, significance, and clarity. Author names and affiliations must not appear in the submissions, and bibliographic references must be adjusted to preserve author anonymity. Submissions failing to comply with paper formatting and authors anonymity will be rejected without reviews.

Because of the double-blind review process, non-anonymous papers that have been issued as technical reports or similar cannot be considered for DSAA'2024. An exception to this rule applies to arXiv papers that were published in arXiv at least a month prior to DSAA'2024 submission deadline. Authors can submit these arXiv papers to DSAA provided that the submitted paper's title and abstract are different from the one appearing in arXiv.