The fusion of scalable computing infrastructure, big data, and artificial intelligence has boosted the development and application of data science and advanced data analytics. However, the recently emerging threats on the privacy, security, and trust (PST) of the data and the analytics models have shown a dramatically increasing trend with the wide deployment of data analytics applications.Specifically, the PST attacks on data or models such as model inversion attacks, membership inference attacks, data poisoning attacks, evasion attacks, and model backdoors, have severely made advanced data analytics highly vulnerable, particularly in common scenarios where data are distributed or computation is outsourced like MLaaS (Machine Learning as a Service). On the other hand, defence solutions are proposed as new computing schemes, PST frameworks, algorithms, and methods. For example, differential privacy, federated learning, and machine unlearning are proposed for privacy protection in data analytics, and adversarial machine learning is proposed to achieve robust, secure, and trustworthy data analytics. Given the importance and urgence, this special issue aims to provide a venue for researchers, practitioners and developers from different background areas relevant to PST and data analytics to exchange their latest experience, research ideas, and synergic research and development on fundamental issues and applications about privacy, security, and trust issues in data analytics, as a strong supplement to the main train of data science and advanced analytics.